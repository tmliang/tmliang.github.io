name: Get Citation Data

on: 
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 30 
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        cd ./google_scholar_crawler
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install -r requirements.txt
      
    - name: Run crawler
      timeout-minutes: 25
      run: |
        cd ./google_scholar_crawler
        source venv/bin/activate
        while true; do
          echo "[$(date)] Still running..." > progress.log
          sleep 300 
        done &
        python main.py
        kill %1
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
    
    - name: Commit results
      run: |
        cd ./google_scholar_crawler/results
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@users.noreply.github.com"
        git add *.json
        git commit -m "Auto-update citation data" || echo "No changes to commit"
        
    - name: Push results
      run: |
        cd ./google_scholar_crawler/results
        git push "https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git" \
          HEAD:google-scholar-stats --force